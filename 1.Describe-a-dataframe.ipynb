{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfaad047-e724-45f4-bb49-e68e9406a6c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Describe a DataFrame\n",
    "\n",
    "Your data processing in Azure Databricks is accomplished by defining Dataframes to read and process the Data.\n",
    "\n",
    "This notebook will introduce how to read your data using Azure Databricks Dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "582e0d4d-c49c-463f-8546-5655b8fd0295",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Introduction\n",
    "\n",
    "** Data Source **\n",
    "* One hour of Pagecounts from the English Wikimedia projects captured August 5, 2016, at 12:00 PM UTC.\n",
    "* Size on Disk: ~23 MB\n",
    "* Type: Compressed Parquet File\n",
    "* More Info: <a href=\"https://dumps.wikimedia.org/other/pagecounts-raw\" target=\"_blank\">Page view statistics for Wikimedia projects</a>\n",
    "\n",
    "**Technical Accomplishments:**\n",
    "* Develop familiarity with the `DataFrame` APIs\n",
    "* Introduce the classes...\n",
    "  * `SparkSession`\n",
    "  * `DataFrame` (aka `Dataset[Row]`)\n",
    "* Introduce the actions...\n",
    "  * `count()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35dc62e4-3218-41ed-a85e-d961141d9a7f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Getting Started\n",
    "\n",
    "Run the following cell to configure our \"classroom.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc69bf37-44dc-46d7-8437-c212afbbc2e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The execution of this command did not finish successfully",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "539cbf7b-54dd-4dcb-b350-ab579ae73b81",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) **The Data Source**\n",
    "\n",
    "* In this notebook, we will be using a compressed parquet \"file\" called **pagecounts** (~23 MB file from Wikipedia)\n",
    "* We will explore the data and develop an understanding of it as we progress.\n",
    "* You can read more about this dataset here: <a href=\"https://dumps.wikimedia.org/other/pagecounts-raw/\" target=\"_blank\">Page view statistics for Wikimedia projects</a>.\n",
    "\n",
    "We can use **dbutils.fs.ls()** to view our data on the DBFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e01f35-91cc-4644-9882-66290ed83a02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1849805626897413>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m (source, sasEntity, sasToken) \u001B[38;5;241m=\u001B[39m getAzureDataSource()\n",
       "\u001B[1;32m      3\u001B[0m spark\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mset(sasEntity, sasToken)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'getAzureDataSource' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1849805626897413>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m (source, sasEntity, sasToken) \u001B[38;5;241m=\u001B[39m getAzureDataSource()\n\u001B[1;32m      3\u001B[0m spark\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mset(sasEntity, sasToken)\n\n\u001B[0;31mNameError\u001B[0m: name 'getAzureDataSource' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'getAzureDataSource' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(source, sasEntity, sasToken) = getAzureDataSource()\n",
    "\n",
    "spark.conf.set(sasEntity, sasToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f62f58d-07e2-4eb1-8ed3-f78a561d2f52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_committed_6241970109963426653</td><td>_committed_6241970109963426653</td><td>760</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_started_6241970109963426653</td><td>_started_6241970109963426653</td><td>0</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00000-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00000-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2996913</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00001-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00001-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2994285</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00002-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00002-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2994196</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00003-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00003-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2992431</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00004-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00004-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2990093</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00005-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00005-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2989931</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00006-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00006-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2989314</td><td>1630966563000</td></tr><tr><td>wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00007-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>part-00007-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet</td><td>2987499</td><td>1630966563000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_SUCCESS",
         "_SUCCESS",
         0,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_committed_6241970109963426653",
         "_committed_6241970109963426653",
         760,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/_started_6241970109963426653",
         "_started_6241970109963426653",
         0,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00000-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00000-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2996913,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00001-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00001-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2994285,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00002-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00002-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2994196,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00003-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00003-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2992431,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00004-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00004-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2990093,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00005-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00005-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2989931,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00006-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00006-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2989314,
         1630966563000
        ],
        [
         "wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net/wikipedia/pagecounts/staging_parquet_en_only_clean/part-00007-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         "part-00007-tid-6241970109963426653-cd9cd6ee-cb10-4da2-82b3-ea25a8369cbf-0-c000.gz.parquet",
         2987499,
         1630966563000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net\"+ \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\"\n",
    "files = dbutils.fs.ls(path)\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ddb6668-33ce-42f7-9902-d8a42e62fe20",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As we can see from the files listed above, this data is stored in <a href=\"https://parquet.apache.org\" target=\"_blank\">Parquet</a> files which can be read in a single command, the result of which will be a `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74020868-ad23-4ad5-bf43-3036c4ac8ab2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Create a DataFrame\n",
    "* We can read the Parquet files into a `DataFrame`.\n",
    "* We'll start with the object **spark**, an instance of `SparkSession` and the entry point to Spark 2.0 applications.\n",
    "* From there we can access the `read` object which gives us an instance of `DataFrameReader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d7134f2-c0c5-43b0-a9f8-c29000e133d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parquetDir = \"wasbs://spark-ui-simulator@dbacademy.blob.core.windows.net\"+ \"/wikipedia/pagecounts/staging_parquet_en_only_clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb4fe6a-d412-4400-9603-f69a7ad089b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[project: string, article: string, requests: int, bytes_served: bigint]\n"
     ]
    }
   ],
   "source": [
    "pagecountsEnAllDF = (spark  # Our SparkSession & Entry Point\n",
    "  .read                     # Our DataFrameReader\n",
    "  .parquet(parquetDir)      # Returns an instance of DataFrame\n",
    ")\n",
    "print(pagecountsEnAllDF)    # Python hack to see the data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e827cad6-b644-488e-8846-4ba2fa0eb2bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) count()\n",
    "\n",
    "If you look at the API docs, `count()` is described like this:\n",
    "> Returns the number of rows in the Dataset.\n",
    "\n",
    "`count()` will trigger a job to process the request and return a value.\n",
    "\n",
    "We can now count all records in our `DataFrame` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0a0822-ce3d-4bfe-a01d-2f8646a5a5a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Count: 2,345,943\n"
     ]
    }
   ],
   "source": [
    "total = pagecountsEnAllDF.count()\n",
    "\n",
    "print(\"Record Count: {0:,}\".format( total ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f53f346-b98b-4c1a-a949-1da639770d9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "That tells us that there are around 2 million rows in the `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee65f6e2-fe81-4d03-8301-70accbd82a4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Start the next lesson, [Use common DataFrame methods]($./2.Use-common-dataframe-methods)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1.Describe-a-dataframe",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
